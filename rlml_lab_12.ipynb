{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amithrajiv/Hackathon/blob/main/rlml_lab_12.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2303A51901\n",
        "\n",
        "M.amith rajiv\n",
        "\n",
        "Batch:- 09\n",
        "\n",
        "Implementing Behavioral Cloning for a simple task using expert demonstrations."
      ],
      "metadata": {
        "id": "Kt8J2W6xdW_g"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f5FD0TxudTRx",
        "outputId": "8583ea1c-2562-4e28-f3cb-a6b4334c3cba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20  loss=0.3156\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/20  loss=0.0957\n",
            "Epoch 3/20  loss=0.0659\n",
            "Epoch 4/20  loss=0.0519\n",
            "Epoch 5/20  loss=0.0410\n",
            "Epoch 6/20  loss=0.0358\n",
            "Epoch 7/20  loss=0.0311\n",
            "Epoch 8/20  loss=0.0291\n",
            "Epoch 9/20  loss=0.0242\n",
            "Epoch 10/20  loss=0.0240\n",
            "Epoch 11/20  loss=0.0217\n",
            "Epoch 12/20  loss=0.0190\n",
            "Epoch 13/20  loss=0.0227\n",
            "Epoch 14/20  loss=0.0231\n",
            "Epoch 15/20  loss=0.0166\n",
            "Epoch 16/20  loss=0.0174\n",
            "Epoch 17/20  loss=0.0159\n",
            "Epoch 18/20  loss=0.0145\n",
            "Epoch 19/20  loss=0.0130\n",
            "Epoch 20/20  loss=0.0161\n",
            "Eval over 30 episodes: mean_return=41.77 std=7.43\n",
            "Model saved to bc_cartpole_gymnasium.pth\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import gymnasium as gym\n",
        "\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "\n",
        "def collect_expert(env_name, n_episodes=200, max_steps=500):\n",
        "    env = gym.make(env_name)\n",
        "    obs_list, act_list = [], []\n",
        "    for _ in range(n_episodes):\n",
        "        o, info = env.reset(seed=random.randint(0, 10**6))\n",
        "        terminated = False\n",
        "        truncated = False\n",
        "        steps = 0\n",
        "        while not (terminated or truncated) and steps < max_steps:\n",
        "            angle = o[2]\n",
        "            a = 1 if angle > 0 else 0\n",
        "            obs_list.append(np.array(o, dtype=np.float32))\n",
        "            act_list.append(int(a))\n",
        "            o, r, terminated, truncated, info = env.step(a)\n",
        "            steps += 1\n",
        "    env.close()\n",
        "    obs = np.vstack(obs_list)\n",
        "    acts = np.array(act_list, dtype=np.int64)\n",
        "    return obs, acts\n",
        "\n",
        "class BCDataset(Dataset):\n",
        "    def __init__(self, observations, actions):\n",
        "        self.x = torch.from_numpy(observations)\n",
        "        self.y = torch.from_numpy(actions)\n",
        "    def __len__(self):\n",
        "        return self.x.shape[0]\n",
        "    def __getitem__(self, idx):\n",
        "        return self.x[idx], self.y[idx]\n",
        "\n",
        "def make_model(obs_dim, n_actions, hidden_sizes=(128,128)):\n",
        "    layers = []\n",
        "    inp = obs_dim\n",
        "    for h in hidden_sizes:\n",
        "        layers.append(nn.Linear(inp, h))\n",
        "        layers.append(nn.ReLU())\n",
        "        inp = h\n",
        "    layers.append(nn.Linear(inp, n_actions))\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "def train_bc(model, dataloader, epochs=10, lr=1e-3, device='cpu'):\n",
        "    model.to(device)\n",
        "    opt = optim.Adam(model.parameters(), lr=lr)\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_loss = 0.0\n",
        "        total = 0\n",
        "        for xb, yb in dataloader:\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "            logits = model(xb)\n",
        "            loss = loss_fn(logits, yb)\n",
        "            opt.zero_grad()\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            total_loss += loss.item() * xb.size(0)\n",
        "            total += xb.size(0)\n",
        "        avg = total_loss / total if total > 0 else 0.0\n",
        "        print(f\"Epoch {epoch+1}/{epochs}  loss={avg:.4f}\")\n",
        "    return model\n",
        "\n",
        "def evaluate_policy(env_name, model, n_episodes=20, max_steps=500, device='cpu', render=False):\n",
        "    render_mode = 'human' if render else None\n",
        "    env = gym.make(env_name, render_mode=render_mode)\n",
        "    model.to(device)\n",
        "    returns = []\n",
        "    for _ in range(n_episodes):\n",
        "        o, info = env.reset(seed=random.randint(0, 10**6))\n",
        "        terminated = False\n",
        "        truncated = False\n",
        "        total_r = 0.0\n",
        "        steps = 0\n",
        "        while not (terminated or truncated) and steps < max_steps:\n",
        "            xb = torch.from_numpy(np.array(o, dtype=np.float32)).unsqueeze(0).to(device)\n",
        "            with torch.no_grad():\n",
        "                logits = model(xb)\n",
        "                a = int(torch.argmax(logits, dim=1).item())\n",
        "            step_out = env.step(a)\n",
        "            if len(step_out) == 5:\n",
        "                o, r, terminated, truncated, info = step_out\n",
        "            else:\n",
        "                o, r, done, info = step_out\n",
        "                terminated, truncated = done, False\n",
        "            total_r += r\n",
        "            steps += 1\n",
        "        returns.append(total_r)\n",
        "    env.close()\n",
        "    mean_return = float(np.mean(returns))\n",
        "    std_return = float(np.std(returns))\n",
        "    print(f\"Eval over {n_episodes} episodes: mean_return={mean_return:.2f} std={std_return:.2f}\")\n",
        "    return returns\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    ENV = \"CartPole-v1\"\n",
        "    obs, acts = collect_expert(ENV, n_episodes=300)\n",
        "    dataset = BCDataset(obs, acts)\n",
        "    loader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
        "    model = make_model(obs_dim=obs.shape[1], n_actions=int(np.max(acts))+1)\n",
        "    model = train_bc(model, loader, epochs=20, lr=1e-3, device='cpu')\n",
        "    evaluate_policy(ENV, model, n_episodes=30)\n",
        "    torch.save(model.state_dict(), \"bc_cartpole_gymnasium.pth\")\n",
        "    print(\"Model saved to bc_cartpole_gymnasium.pth\")\n"
      ]
    }
  ]
}